import numpy as np
from scipy.stats import norm
from get_cpp import get_cpp

#  Performs approximate Bayesian latent state inference for the change-point task
# 
#  Description:
#  Inputs
    # data - vector of obs. generated by seq. of latent states w/ Gaussian emission noise
    # ps   - structure with fields for subject parameters controlling how the subject behaves
# 
#  Parameter inputs (see code for defaults):
    # ps.mix             - mixture param in [0,1] for Bayes (1) vs delta-rule beliefs (0)
    # ps.mix_method      - sets meaning of mix, set to 'exp' or 'linear', see code for details
    # ps.drift           - assumed Brownian noise variance in latent state
    # ps.hazard          - assumed hazard rate of latent state changepoints
    # ps.unc_from_len    - boolean determining how runlen should be computed
    # ps.init_state_est  - initial latent state estimate
    # ps.init_runlen_est - initial runlen estimate;
    # ps.noise_sd        - assumed Gaussian noise standard dev. for emission (observation) model
    # ps.noise_sd_lr     - additive Gaussian noise in learning rate (applied to state update)
    # ps.noise_sd_update - additive Gaussian noise in state estimate update
    # ps.lr_const        - constant added to learning rate which is not derived from hazard
    # ps.clip            - clip off the final runlength est (so that it has same length as PE)
    # ps.limit_updates   - limit bin updates to be between last placement and current observation 
# 
#  Returns a structure (beliefs) with fields:
    # pred     - estimated latent state after every observation
    # cpp      - estimated change point probability after every observation
    # runlen   - estimated time latent state has spent at current state estimate
    # obs_sd   - estimated uncertainty of next observation as Gaussian standard dev.
    # state_sd - estimated uncertainty of latent state as Gaussian standard dev
    # relunc   - relative state uncertainty, i.e. 1/(runlen + 1)
    # pe       - state prediction error on observing each trial
    # lr       - learning rate for update after observing each trial
    # update   - latent state update performed
# 
#  Authors:
    # Matt R. Nassar, UPENN, 2009 (original)
    # Daniel N. Scott & Niloufar Razmi, Nassar Lab, Brown University, 2022 (update)
# 
#  Notes:
    # Currently, mixture parameter does nothing (I modified the code slightly) for inclusion in 
    # the BG-CPT repository, removing more complex, parameterized CPP calculations. I also haven't
    # verified that it still runs. If not, Qin and I can sort it out.

class def_ps:
    def __init__(self, sigma):
        # Default parameters
        self.model           = 'exp';      # Model for subject CPP estimation
        self.mix             = 1;          # Likelihood/optimality param in [0,1]. 1 is optimal.
        self.clip            = 1;          # Clip runlen and relunc to trial-length vec
        self.limit_updates   = 0;          # Limit updates to be within previous pred and new obs

        self.drift           = 0;          # Drift rate in bin units
        self.unc_from_len    = 0;          # Compute uncertainty from runlength?
        self.init_state_est  = 150;        # Trial 1 bucket placement
        self.init_runlen_est = 0.01;        # Initialization for runlength estimate
        self.init_ru         = 0.1;        # Initialization for relunc in cases where that's used
        self.ud              = 1;          # Uncertainty divisor

        self.hazard          = 0.1;        # Hazard rate P(CP)
        self.noise_sd        = sigma;         # Emission noise in bin units
        self.noise_sd_lr     = 0.0;        # Multiplicative LR noise in [0,1]
        self.noise_sd_update = 2;          # Motor noise in bin units
        self.lr_const        = 0.0;        # Constant added to learning rate 

        self.loc             = 0;          # Sigmoid CPP model location parameter
        self.unc             = 1;          # Sigmoid CPP model uncertainty multiplier

class def_blf:
    def __init__(self):
        # Default parameters
         # Package for output... these three are observable:
        self.pred     = 0
        self.pe       = 0
        self.update   = 0

        self.runlen   = 0
        self.relunc   = 0
        self.cpp      = 0
        self.lr       = 0
        self.obs_sd   = 0
        self.state_sd = 0
        self.data     = 0
        

def def_subj_params(sigma):
    ps = def_ps(sigma)
    return ps

def get_runlen_est(obs, pred, pe, cpp, relunc, runlen_est, noise_var):
    stay_prob = 1 - cpp
    ss = cpp* noise_var +\
         stay_prob * noise_var / (runlen_est + 1) +\
         cpp* stay_prob * ((pred + relunc*pe) - obs)**2
  
    runlen_est = noise_var/ss

    return runlen_est

def get_beliefs(data, beliefs, manual_PE, sigma):
    # initializations
    ps = def_subj_params(sigma)

    # Number of trials in the data
    n_trials = len(data)

    # Initialize belief matrices
    pred       = np.full((n_trials + 1, 1), np.nan)
    runlen_est = np.full((n_trials + 1, 1), np.nan)
    relunc     = np.full((n_trials, 1), np.nan)
    cpp_est    = np.full((n_trials, 1), np.nan)
    state_var  = np.full((n_trials, 1), np.nan)
    obs_sd     = np.full((n_trials, 1), np.nan)
    pe         = np.full((n_trials, 1), np.nan)
    update     = np.full((n_trials, 1), np.nan)
    learn_rate = np.full((n_trials, 1), np.nan)

    # Initialize actual beliefs
    pred[0]       = ps.init_state_est
    runlen_est[0] = ps.init_runlen_est

    # Bounds on location of latent state (and observations)
    bnds = [0, 300]

    # Noise SD is always used as variance
    noise_var = ps.noise_sd**2

    #  Loop through the observations, making sequential predictions
    for i in range(n_trials):
        # Part 1: get the expected distribution of observations
        
        # Latent state uncertainty without drift
        static_var = noise_var / runlen_est[i]
        
        # Latent state uncertainty considering drift
        state_var[i] = static_var + ps.drift

        # Updated belief in how long runs should last
        runlen_est[i] = noise_var / state_var[i]

        # Uncertainty on the next observation
        obs_sd[i] = np.sqrt(noise_var + state_var[i])


        # Part 2: calculate probability of latent state change
        cpp_est[i] = get_cpp(data[i], pred[i], obs_sd[i], ps.hazard, bnds)


        # Part 3: Update belief about mean
        
        # Now run_len_est can be really small if there is a big drift...
        relunc[i]  = 1/(runlen_est[i] + 1)

        # Find learning rate
        noise_lr      = norm.rvs(0, ps.noise_sd_lr)
        learn_rate[i] = min(max(relunc[i] + cpp_est[i] - cpp_est[i]*relunc[i] + ps.lr_const, 0), 1)

        # Learning rate noise should probably not reverse update dir.
        proposal = learn_rate[i] + noise_lr
        if np.sign(proposal) == np.sign(learn_rate[i]):
            learn_rate[i] = proposal
        else:
            learn_rate[i] = 0
        
        # Set state prediction error
        pe[i] = data[i] - pred[i]

        # Update state estimate
        noise_update = norm.rvs(0, ps.noise_sd_update)
        update[i]    = learn_rate[i]*pe[i] + noise_update
        pred[i+1]    = pred[i] + update[i]
        if i == len(data) - 3:
            data[i+1] = pred[i+1] + manual_PE
            data[i+2] = pred[i+1] + manual_PE

        # Apply limits if task has them
        if ps.limit_updates:
            min_pred = min(pred[i], data[i])
            max_pred = max(pred[i], data[i])
            pred[i+1] = max(min(pred[i+1], max_pred), min_pred)

        # Part 4: Update run length
        runlen_est[i+1] = get_runlen_est(data[i], pred[i], pe[i], cpp_est[i], relunc[i], runlen_est[i], noise_var)

    # Lots of calcs are easier w/o the final runlen/relunc number
    if ps.clip:
        runlen_est = runlen_est[0:-1]

    # Package for output... these three are observable:
    beliefs.pred     = pred
    beliefs.pe       = pe
    beliefs.update   = update

    # Package for output... these need to be inferred for real subjects:
    beliefs.runlen   = runlen_est
    beliefs.relunc   = 1/(runlen_est + 1)
    beliefs.cpp      = cpp_est
    beliefs.lr       = learn_rate
    beliefs.obs_sd   = obs_sd
    beliefs.state_sd = np.sqrt(state_var)
    beliefs.data     = data

